{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annoying-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.datasets\n",
    "\n",
    "def get_iris_df():\n",
    "    ds = sklearn.datasets.load_iris()\n",
    "    df = pd.DataFrame(ds['data'],columns=ds['feature_names'])\n",
    "    code_species_map = dict(zip(range(3), ds['target_names']))\n",
    "    df['species'] = [code_species_map[c] for c in ds['target']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_iris_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assigned-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  species  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-score",
   "metadata": {},
   "source": [
    "# decision tree\n",
    "\n",
    "> 특정 기준(질문)에 따라 데이터를 구분하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-alert",
   "metadata": {},
   "source": [
    "\n",
    "결정 트리를 학습하는 방법은 다음과 같습니다.\n",
    "\n",
    "1. 데이터를 보고 분류를 잘하는 최적의 특징값과 기준을 찾아냅니다.\n",
    "2. 분류가 잘되었는지 평가하는 방법은 다양합니다. 가장 흔히 사용하는 방법은 정보 이득과 지니 불순도입니다.\n",
    "3. 이렇게 찾아낸 최적의 특징값과 기준은 결정 트리의 최상위 노드가 됩니다.\n",
    "4. 이 작업을 계속 반복해 데이터를 나눕니다.\n",
    "5. 더 이상 데이터를 나눌 필요가 없어지거나 미리 정해놓은 트리의 높이에 도달하면 멈춥니다. 각 단말 노드에 있는 데이터 분포가 해당 노드의 확률분포가 됩니다. 예를 들어 잎사귀 노드에 범주 1의 데이터가 30개, 범주 2의 데이터가 20개 있다면 범주가 1/2일 확률을 각각 60%, 40%로 계산합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-sussex",
   "metadata": {},
   "source": [
    "- 결정 트리의 구체적인 학습 방법을 알아 두면 과적합과 같은 문제에 대처하는 데 도움이 됩니다.\n",
    "- 예를 들어 트리의 최대 높이를 너무 크게 설정하면 잎사귀 노드마다 아주 적은 데이터 표본만 포함하게 됩니다. 결과적으로 100%에 가까운 예측 확률을 얻게 되는데 실제로 정확도가 올라간 것이 아니라 과적합이 일어난 겁니다.\n",
    "- 라이브러리의 기본 설정을 그대로 사용하면 이런 문제가 흔히 발생하기 때문에 세부 매개변수를 조절하려면 학습 원리를 알고 있어야 합니다.\n",
    "\n",
    "`과적합 : 머신러닝 모델이 학습 데이터에 너무 치우쳐서 일반화하지 못하게 된 것`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-bacon",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(train[indep_cols],train.breed)\n",
    "predictions = clf.predict(test[indep_cols])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "willing-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier   \n",
    "from sklearn.datasets import load_iris    \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "equivalent-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "\n",
    "iris_data=load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precise-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DecisionTreeClassifier\n",
    "clf= DecisionTreeClassifier(max_depth=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aerial-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train clf\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "measured-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.992\n",
      "테스트 세트 정확도: 0.967\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-chicken",
   "metadata": {},
   "source": [
    "# random forest\n",
    "\n",
    "> 각기 다른 학습 데이터를 이용해 학습한 결정 트리를 모아놓은 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-theater",
   "metadata": {},
   "source": [
    "- 가지고 있는 데이터를 무작위로 나눠서 결정 트리 여러 개를 학습시킵니다.\n",
    "- 예측은 여러 결정 트리의 평균 예측값을 사용합니다.\n",
    "- 앙상블 분류기의 좋은 예입니다.\n",
    "\n",
    "`앙상블 분류기 : 분류기 여러 개를 학습시키고 그 결과를 합쳐서 예측값을 정하는 분류 방법`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-drilling",
   "metadata": {},
   "source": [
    "이 방법은 결정 트리 여러 개가 서로 다른 특징을 찾아내고 결정 트리의 의견을 많이 모아서 다수결을 따르면 잘 작동할 것이라고 가정합니다.\n",
    "설령 과적합이 발생하더라도 트리마다 다른 과적합이 일어나는데 이것 역시 여러 트리를 모으면 상쇄된다는 원리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-breeding",
   "metadata": {},
   "source": [
    "### 단점\n",
    "- 결정트리의 단점과 비슷합니다. 학습된 랜덤 포레스트 분류기로 데이터에 대한 통찰을 얻기가 매우 어렵습니다.\n",
    "- 특징값의 중요성을 쉽게 계산할 수 있지만 특징값이 데이터에서 정확히 어떤 의미를 지니는지 파악이 어렵습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-telephone",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(\n",
    "    max_depth=5,n_estimators=10,\n",
    "    max_features=1)\n",
    "clf.fit(train[indep_cols], train.breed)\n",
    "predictions = clf.predict(test[indep_cols])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-anxiety",
   "metadata": {},
   "source": [
    "Parameter (Python의 sklearn 라이브러리 기준)\n",
    "\n",
    "- N-estimator : 랜덤포레스트 안에 만들어지는 의사결정나무 갯수. 트리가 많아지면 속도가 느려지고 너무 트리가 크면 오히려 정확도가 낮아진다. 그러나 일반적으론 트리가 많아질수록 분류를 잘하게 되므로 적절한 trade-off 필요하다.\n",
    "\n",
    "- Max-depth : 랜덤포레스트 안에 있는 각 의사결정나무의 깊이를 설정. 트리가 깊어질수록 더 잘게 분류를 시키므로 일반적으론 정확도가 높아진다.\n",
    "\n",
    "- Min-samples-split : 내부 노드에 데이터를 얼마 만큼씩 최소한 넣을 것인가 설정. 10%~100%로 설정. 100%로 갈수록 underffiting이 일어나서 정확도가 낮아진다. \n",
    "\n",
    "- Min-samples-leaf : 리프 노드에 데이터를 얼마 만큼씩 최소한 넣을 것인가 설정. 10%~100%로 설정. 100%로 갈수록 underffiting이 일어나서 정확도가 낮아진다.\n",
    "\n",
    "- Max-feature : 가장 잘 분류할 feature의 갯수를 설정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gothic-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "interim-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "\n",
    "iris_data=load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cross-compensation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    max_depth=5, n_estimators=10,\n",
    "    max_features=1)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "greenhouse-garden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.992\n",
      "테스트 세트 정확도: 0.967\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
